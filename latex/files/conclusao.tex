\chapter{Resultados}

% Falar da implementação (PyTorch)

Foi feita a implementação do
método de Síntese de Textura
usando a abordagem das matrizes
de Gram. 
Para isso foi utilizada 
a linguagem Python com a
biblioteca PyTorch.
O PyTorch reúne uma série de
funções que facilitaram
a implementação do método.
As principais foram: implementação
nativa da rede VGG-19, operações
aritméticas aceleradas na GPU,
cálculo automático de gradiente,
e implementação do método de
otimização L-BFGS.
O código utilizado, bem como
as texturas, estão disponíveis
em \url{https://github.com/danilolc/texture-synthesis}.
O arquivo principal é o \textit{texture\_synth.py},
que pode ser modificado para
executar as diferentes implementações
do trabalho.

% Escolha de textura

A primeira ideia era escolher um
conjunto de textura de resolução
$128 \times 128$ e tentar gerar
imagens de $256 \times 256$ pixels.
Foram escolhidos um conjunto de
diferentes tipos de texturas 
para explorar o comportamento
do algoritmo.

% Mostrar os resultados

%Em todos os testes a primeira imagem é
%a amostra, e as seguintes são passos (não
%necessariamente consecutivos) do
%algoritmo de otimização.

\begin{figure}[!ht]
	\centering
	\includegraphics[width=\linewidth]{files/assets/results/result2.png}
	\includegraphics[width=\linewidth]{files/assets/results/result5.png}
	\caption{Teste com texturas mais caóticas. A primeira imagem
	é a amostra, e as seguintes são sínteses a medida que
	o número de iterações cresce.
	No processo, a escala dos objetos se mantém, portanto, o resultado
	terá quatro vezes mais informação.}
	\label{img:preview}
\end{figure}


\begin{figure}[!ht]
	\centering
	\includegraphics[width=\linewidth]{files/assets/results/result1.png}
	\includegraphics[width=\linewidth]{files/assets/results/result3.png}
	\caption{O método não funciona bem em textura com 
	estrutura regular global, ele dá preferência por
	estruturas locais. }
	\label{img:presente}
\end{figure}



\begin{figure}[!ht]
	\centering
	\includegraphics[width=\linewidth]{files/assets/results/result4.png}
	\caption{Nuvens apresentam uma estrutura caótica
	ideal para esse método.}
	\label{nuuv}
\end{figure}
% Falar da animação

\newpage
As iterações foram feitas até que não fosse possível perceber
diferenças na imagem entre os passos de iteração.
Todos os testes feitos convergiram para algum valor, que
nem sempre mostrava a textura de forma ideal (como pode
ser visto na Figura \ref{img:presente}).
Com isso foi pensado
em adicionar ruído na imagem em intervalos fixos de iterações
para forçar a mudança do ponto de convergência.
Isso gerou um resultado interessante ao movimentar
suavemente a textura a cada aplicação do ruído,
como mostra a Figura \ref{img:nuvem}.

\begin{figure}[!ht]
	\centering
	\includegraphics[width=\linewidth]{files/assets/results/result6.png}
	\caption{A terceira imagem foi gerada a partir da adição de ruído
		na segunda, assim como da terceira para quarta e da quarta para
		quinta. 
		Com isso, a sequência de imagens se comporta de um modo
		semelhante ao movimento de nuvens.}
	\label{img:nuvem}
\end{figure}

% Teste com imagens não textura

\newpage
Não é preciso se limitar a texturas com
esse tipo de implementação. É possível verificar
o que acontece no resultado com imagens não textura, 
como feito na Figura \ref{nontex}.
O resultado do método nessas imagens preserva
cores e pequenos objetos, mas não reproduzem
a informação espacial da imagem.

\begin{figure}[!ht]
	\centering
	\includegraphics[width=\linewidth]{files/assets/results/result7.png}
	\includegraphics[width=\linewidth]{files/assets/results/result8.png}
	\caption{Teste de Síntese de Textura com imagem não textura.}
	\label{nontex}
\end{figure}

Todos os testes foram executados em um notebook
Dell G3 3590, com um processador Intel Core i5-9300H
em 2,4GHz e uma placa de vídeo (GPU) NVIDIA GeForce GTX 1050
de 3 GB de memória.
Importar o modelo VGG-19 (depois de baixado) 
e calcular as matrizes de Gram
da amostra é feito quase instantaneamente.
É possível escolher entre rodar o modelo no processador
(CPU) ou na placa de vídeo (CUDA). No segundo
o método converge em poucos segundos,
como mostra a Tabela \ref{tabela}.


\begin{table}[ht]
	\centering
	\caption{Tempo de execução para gerar a imagem da Figura \ref{nuuv}
	(uma imagem de resolução 256x256).
	O resultado convergiu a partir de 18 iterações do L-BFGS.}
	\label{tabela}
	\begin{centering}
		\begin{tabularx}{\textwidth*2/3}{||X|c|c||}
			\hline Dispositivo & Tempo total & Tempo por iteração \\
			\hline CPU & 267s & 14,8s/it \\
			\hline CUDA & 40s & 2,2s/it \\
			\hline
		\end{tabularx}
	\end{centering}
\end{table}

Não exite uma forma fechada de comparar a qualidade
do resultado, assim a melhor maneira de verificar
se o método funciona bem para a textura dada
é comparando os resultados visualmente e julgando-os
com base na percepção.

% Style transfer
Uma vez implementada a síntese de textura, implementar
a transferência de estilo passa a ser trivial,
apenas tendo que adicionar a diferença das \textit{features}
na função de perda. Os resultados deste método são mostrados nas
figuras a seguir.



\begin{figure}[!ht]
	\centering
	\includegraphics[width=\linewidth]{files/assets/results/air1.png}
	\includegraphics[width=\linewidth]{files/assets/results/galinha1.png}
	\caption{Resultado de transferência de estilo, a primeira imagem
	é usada como estilo e a segunda como conteúdo. O resultado
	depende da escala das duas imagens.}
	\label{img:preview}
\end{figure}
\begin{figure}[!ht]
	\centering
	\includegraphics[width=\linewidth]{files/assets/results/magali.png}
	\includegraphics[width=\linewidth]{files/assets/results/galinha2.png}
	\caption{Mais resultados de transferência de estilo. Na última é
	possível ver que o método não fica restrito a texturas.}
	\label{img:preview}
\end{figure}




\chapter{Conclusão}

Esse trabalho mostrou o quanto
pode ser difícil a tarefa de
processamento e síntese
de texturas e imagens no geral,
e o quanto foi preciso andar
para chegar nos avanços que
existem hoje.
Uma grande quantidade de trabalhos
são publicados todos os anos
na área, cada um tentando
encontrar uma maneira nova de
melhorar a solução do problema.

Redes Neurais e \textit{Deep Learning}
vêm se mostrando ferramentas
bem poderosas para o trabalho com imagem.
A diferença entre as camadas de
Redes Convolucionais pré-treinadas
para a detecção de objetos
podem oferecer uma excelente
métrica perceptual, abrindo caminho para
diversos novos trabalhos.
O aprendizado automático
de representações facilita
o trabalho de criar aplicações
de processamento e síntese de imagens,
mas a disponibilidade de dados
e de processamento ainda pode ser
um problema.

% A principal vantagem de
% Redes neurais é aprender
% métricas perceptuais

% Redes neurais pre-treinadas
% não são apenas para classificação

Ferramentas para trabalhar
com \textit{Machine Learning} como o
PyTorch vêm se mostrando
mais poderosas
a cada dia, oferecendo
facilidades para trabalhar 
com grandes quantidades de dados,
além de fácil acesso à GPU,
que melhora bastante a velocidade
de operações aritméticas.
Essas ferramentas também 
contam com sistemas de cálculo automático
de gradiente, tornando o trabalho
de otimização mais fácil e
menos suscetível a erros.




% PyTorch é uma boa ferramenta
% de deep learning, GPU acelera


%\section{Perspectivas}
% Definir depois